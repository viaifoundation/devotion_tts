# gen_prayer_cosy.py
# Local offline CosyVoice-300M for Prayer (Paragraph Rotation)
import torch
import numpy as np
import re
import sys
import os
import warnings
from datetime import datetime
from pydub import AudioSegment

# Silence noisy libraries
warnings.filterwarnings("ignore", category=FutureWarning, module="diffusers")
warnings.filterwarnings("ignore", category=UserWarning, module="lightning")

# Setup path to find CosyVoice (sibling directory)
COSYVOICE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "../CosyVoice"))
MATCHA_PATH = os.path.join(COSYVOICE_PATH, "third_party", "Matcha-TTS")

if os.path.exists(COSYVOICE_PATH):
    sys.path.append(COSYVOICE_PATH)
    if os.path.exists(MATCHA_PATH):
        sys.path.append(MATCHA_PATH)
else:
    print(f"âš ï¸ Warning: CosyVoice path not found at {COSYVOICE_PATH}")
    sys.exit(1)

try:
    from cosyvoice.cli.cosyvoice import CosyVoice
except ImportError as e:
    print(f"âŒ Failed to import CosyVoice: {e}")
    sys.exit(1)

from bible_parser import convert_bible_reference
from date_parser import convert_dates_in_text
from text_cleaner import clean_text
import filename_parser
import audio_mixer

ENABLE_BGM = False
BGM_FILE = "AmazingGrace.MP3"

TEXT = """
â€œçŠ¹å¤§åœ°çš„ä¼¯åˆ©æ’å•Šï¼Œ ä½ åœ¨çŠ¹å¤§è¯¸åŸŽä¸­å¹¶ä¸æ˜¯æœ€å°çš„ï¼› å› ä¸ºå°†æ¥æœ‰ä¸€ä½å›çŽ‹è¦ä»Žä½ é‚£é‡Œå‡ºæ¥ï¼Œ ç‰§å…»æˆ‘ä»¥è‰²åˆ—æ°‘ã€‚ã€â€
â€­â€­é©¬å¤ªç¦éŸ³â€¬ â€­2â€¬:â€­6â€¬ â€­CUNPSS-ç¥žâ€¬â€¬

ç¥žäº²çˆ±çš„ä¸»è€¶ç¨£åŸºç£ï¼Œæˆ‘ä»¬åœ¨çºªå¿µä½ è¯žç”Ÿçš„æ—¥å­å‘ä½ æ„Ÿæ©ï¼Œå› ä½ çš„è¯žç”Ÿç»™æˆ‘ä»¬å¸¦æ¥äº†æ°¸æ´»çš„æ³‰æºï¼Œæ›´ä¸ºæˆ‘ä»¬å¸¦æ¥äº†æ°¸ç”Ÿçš„ç›¼æœ›ï¼Œä¸»å•Šï¼Œæˆ‘ä»¬ä¸ºæŠŠä½ æ—¨æ„ä¼ éä¸–ç•Œï¼Œä¹¡éŸ³æ›´å¥½çš„ä¸ºä¸»çš„ç¦éŸ³åšäº†ç¾Žå¥½æ¦œæ ·ï¼Œä¸»å•Šï¼Œä½ çš„é“è·¯é«˜è¿‡ä»»ä½•äººçš„é“è·¯ï¼Œä¹¡éŸ³å°±æ˜¯å¥‰ä¸»çš„åèµ°ä¸»ä½ å¼•é¢†çš„é“è·¯ï¼Œå¸¦é¢†æ›´å¤šçš„äººä¿¡ä¸»ï¼Œä¸ºä¸»åšäº†ç¾Žå¥½çš„è§è¯ï¼Œä¸»ï¼Œæ±‚ä½ ä¸ºä»Šå¹´çš„ä¹¡éŸ³é¢„å¤‡å„æ ·çš„èµ„æºï¼Œå¹¶ð§¶½ä¸åŒåœ°åŒºåŒå·¥ä»¬åˆä¸€ç­”é…çš„å¿ƒï¼ŒæŠŠä¸»çš„ç¦éŸ³ä¼ åˆ°åœ°æžï¼Œæˆ‘ä»¬è¿™æ ·çš„ç¥·å‘Šï¼Œæ˜¯å¥‰ä¸»åŸºç£çš„åã€‚é˜¿ä»¬ï¼
"""


print("Loading CosyVoice-300M-Instruct (local offline)...")
try:
    use_fp16 = torch.cuda.is_available()
    print(f"Loading CosyVoice-300M-Instruct... [CUDA={use_fp16}, FP16={use_fp16}]")
    cosyvoice = CosyVoice('iic/CosyVoice-300M-Instruct', fp16=use_fp16)
except Exception as e:
    print(f"âŒ Error loading model: {e}")
    print("Ensure you have 'modelscope' installed.")
    sys.exit(1)



# Generate filename dynamically
first_line = TEXT.strip().split('\n')[0]
date_match = re.search(r"(\d{1,2})/(\d{1,2})/(\d{4})", TEXT)
if date_match:
    m, d, y = date_match.groups()
    date_str = f"{y}-{int(m):02d}-{int(d):02d}"
else:
    date_match = re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", TEXT)
    if date_match:
        y, m, d = date_match.groups()
        date_str = f"{y}-{int(m):02d}-{int(d):02d}"
    else:
        date_str = datetime.today().strftime("%Y-%m-%d")

# 2. Extract Verse
verse_ref = filename_parser.extract_verse_from_text(TEXT)

if verse_ref:
    # Remove VOTD prefix if filename_parser adds it
    raw_filename = filename_parser.generate_filename(verse_ref, date_str)
    if raw_filename.startswith("VOTD_"):
        raw_filename = raw_filename[5:]
    filename = f"SOH_Sound_of_Home_Prayer_{raw_filename.replace('.mp3', '')}_cosy.mp3"
else:
    filename = f"SOH_Sound_of_Home_Prayer_{date_str}_cosy.mp3"

OUTPUT_DIR = os.path.join(os.getcwd(), "output")
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
OUTPUT_PATH = os.path.join(OUTPUT_DIR, filename)
print(f"Target Output: {OUTPUT_PATH}")

TEXT = convert_bible_reference(TEXT)
TEXT = convert_dates_in_text(TEXT)
TEXT = clean_text(TEXT)

paragraphs = [p.strip() for p in re.split(r'\n{2,}', TEXT.strip()) if p.strip()]

# Voice Rotation (Mixing genders and cross-lingual for variety)
voices = ["ä¸­æ–‡å¥³", "è‹±æ–‡ç”·", "ä¸­æ–‡ç”·", "æ—¥è¯­ç”·", "ç²¤è¯­å¥³"]

def speak(text: str, voice: str) -> AudioSegment:
    print(f"DEBUG: Text to read: {text[:100]}...")
    print(f"   Synthesizing ({len(text)} chars) with {voice}...")
    # SFT Inference
    output_gen = cosyvoice.inference_sft(text, voice)
    
    final_audio = AudioSegment.empty()
    for item in output_gen:
        if 'tts_speech' in item:
            audio_np = item['tts_speech'].numpy()
            audio_int16 = (audio_np * 32767).astype(np.int16)
            segment = AudioSegment(
                audio_int16.tobytes(),
                frame_rate=22050, 
                sample_width=2,
                channels=1
            )
            final_audio += segment
    return final_audio

final_mix = AudioSegment.empty()
silence = AudioSegment.silent(duration=800, frame_rate=22050)

print(f"Processing {len(paragraphs)} paragraphs with voice rotation...")

for i, para in enumerate(paragraphs):
    voice = voices[i % len(voices)]
    print(f"  > Para {i+1} - {voice}")
    
    try:
        segment = speak(para, voice)
        final_mix += segment
        if i < len(paragraphs) - 1:
            final_mix += silence
    except Exception as e:
        print(f"âŒ Error generating para {i}: {e}")

# Upsample to 24k for consistency
final_mix = final_mix.set_frame_rate(24000)

# Add Background Music (Optional)
if ENABLE_BGM:
    print("ðŸŽµ Mixing Background Music...")
    final_mix = audio_mixer.mix_bgm(final_mix, specific_filename=BGM_FILE)
else:
    print("ðŸŽµ Background Music: Disabled (ENABLE_BGM=False)")

# Metadata extraction
PRODUCER = "VI AI Foundation"
TITLE = TEXT.strip().split('\n')[0]

final_mix.export(OUTPUT_PATH, format="mp3", bitrate="192k", tags={'title': TITLE, 'artist': PRODUCER})
print(f"âœ… Saved: {OUTPUT_PATH}")
