# gen_verse_devotion_cosy.py
# Local offline CosyVoice-300M â€“ 5 voices for verse devotion

import torch
import numpy as np
import re
import sys
import os
import warnings
from datetime import datetime

# Silence noisy libraries
warnings.filterwarnings("ignore", category=FutureWarning, module="diffusers")
warnings.filterwarnings("ignore", category=UserWarning, module="lightning")

from pydub import AudioSegment

# Setup path to find CosyVoice (sibling directory)
# and its third_party dependencies (Matcha-TTS)
COSYVOICE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "../CosyVoice"))
MATCHA_PATH = os.path.join(COSYVOICE_PATH, "third_party", "Matcha-TTS")

if os.path.exists(COSYVOICE_PATH):
    sys.path.append(COSYVOICE_PATH)
    # Also add Matcha-TTS to path as CosyVoice imports 'matcha' directly
    if os.path.exists(MATCHA_PATH):
        sys.path.append(MATCHA_PATH)
    else:
        print(f"âš ï¸ Warning: Matcha-TTS not found at {MATCHA_PATH}")
        print("Run: cd ../CosyVoice && git submodule update --init --recursive")
else:
    print(f"âš ï¸ Warning: CosyVoice path not found at {COSYVOICE_PATH}")
    print("Please clone it: git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git ../CosyVoice")

try:
    from cosyvoice.cli.cosyvoice import CosyVoice
    from cosyvoice.utils.file_utils import load_wav
except ImportError as e:
    print(f"âŒ Failed to import CosyVoice: {e}")
    print(f"Ensure you have cloned the repo to {COSYVOICE_PATH} and installed its requirements.")
    sys.exit(1)

# -----------------------------------------------------------------------------
# Runtime Patch: Enable MPS (Metal) Support for macOS
# -----------------------------------------------------------------------------
try:
    from cosyvoice.cli.model import CosyVoiceModel
    original_init = CosyVoiceModel.__init__

    def patched_init(self, llm, flow, hift, fp16=False):
        # Call original init (sets gpu or cpu)
        original_init(self, llm, flow, hift, fp16)
        # Check for MPS and override if available
        if torch.backends.mps.is_available():
            print("ðŸš€ MPS (Metal Performance Shaders) detected! Enabling Mac GPU acceleration...")
            self.device = torch.device('mps')
            # Move submodules to MPS
            self.llm = self.llm.to(self.device)
            self.flow = self.flow.to(self.device)
            self.hift = self.hift.to(self.device)
    
    # Apply patch
    CosyVoiceModel.__init__ = patched_init
except ImportError:
    pass # CosyVoice not found or structure changed

from bible_parser import convert_bible_reference
from date_parser import convert_dates_in_text
from text_cleaner import remove_space_before_god
import filename_parser

print("Loading CosyVoice-300M-Instruct (local offline)...")
# CosyVoice automatically handles model download via modelscope if not present
try:
    # Auto-enable FP16 if CUDA is available for speed
    use_fp16 = torch.cuda.is_available()
    print(f"Loading CosyVoice-300M-Instruct (local offline)... [CUDA={use_fp16}, FP16={use_fp16}]")
    cosyvoice = CosyVoice('iic/CosyVoice-300M-Instruct', fp16=use_fp16)
except Exception as e:
    print(f"âŒ Error loading model: {e}")
    print("Ensure you have 'modelscope' installed and dependencies met.")
    sys.exit(1)

TEXT = """
å¿è€ç”Ÿç”˜ç”œ (é›…å„ä¹¦ 5:8) 12/14/2025

ã€€ç¥žè¯´ï¼šâ€œè¦æœ‰å…‰â€ï¼Œå°±æœ‰äº†å…‰ã€‚
(åˆ›ä¸–è®° 1:3 )
å¤§å±±å¯ä»¥æŒªå¼€ï¼Œ
å°å±±å¯ä»¥è¿ç§»ï¼›
ä½†æˆ‘çš„æ…ˆçˆ±å¿…ä¸ç¦»å¼€ä½ ï¼›
æˆ‘å¹³å®‰çš„çº¦ä¹Ÿä¸è¿ç§»ã€‚
è¿™æ˜¯æ€œæ¤ä½ çš„è€¶å’ŒåŽè¯´çš„ã€‚
(ä»¥èµ›äºšä¹¦ 54:10)
ä¸»ä¸ºæˆ‘ä»¬èˆå‘½ï¼Œæˆ‘ä»¬ä»Žæ­¤å°±çŸ¥é“ä½•ä¸ºçˆ±ï¼›æˆ‘ä»¬ä¹Ÿå½“ä¸ºå¼Ÿå…„èˆå‘½ã€‚
(çº¦ç¿°ä¸€ä¹¦ 3:16)
â€œã€€ç¥žçˆ±ä¸–äººï¼Œç”šè‡³å°†ä»–çš„ç‹¬ç”Ÿå­èµç»™ä»–ä»¬ï¼Œå«ä¸€åˆ‡ä¿¡ä»–çš„ï¼Œä¸è‡³ç­äº¡ï¼Œåå¾—æ°¸ç”Ÿã€‚
(çº¦ç¿°ç¦éŸ³ 3:16)

å¼Ÿå…„ä»¬å“ªï¼Œä½ ä»¬è¦å¿è€ï¼Œç›´åˆ°ä¸»æ¥ã€‚çœ‹å“ªï¼Œå†œå¤«å¿è€ç­‰å€™åœ°é‡Œå®è´µçš„å‡ºäº§ï¼Œç›´åˆ°å¾—äº†ç§‹é›¨æ˜¥é›¨ã€‚ä½ ä»¬ä¹Ÿå½“å¿è€ï¼Œåšå›ºä½ ä»¬çš„å¿ƒï¼Œå› ä¸ºä¸»æ¥çš„æ—¥å­è¿‘äº†ã€‚
(é›…å„ä¹¦ 5:7-8 å’Œåˆæœ¬)
ä½ ä»¬ä¹Ÿåº”å½“å¿è€ï¼Œåšå®šè‡ªå·±çš„å¿ƒï¼›å› ä¸ºä¸»å†æ¥çš„æ—¥å­è¿‘äº†ã€‚
(é›…å„ä¹¦ 5:8 æ–°è¯‘æœ¬)

å¿è€ç”Ÿç”˜ç”œ

ä½ æ›¾åœ¨æ°´æžœæœªç†Ÿæ—¶å°±æŠŠå®ƒé‡‡æ‘˜ä¸‹æ¥åƒå—ï¼Ÿ

ä¹Ÿè®¸ä½ è¢«å®ƒé²œè‰³çš„è‰²å½©å’Œç©ºæ°”ä¸­å¼¥æ¼«çš„ç”œç¾Žæ°”å‘³æ‰€å¸å¼•ã€‚å¯æƒœä½ ä¸€å£å’¬ä¸‹åŽ»ï¼Œå´å‘çŽ°å®ƒæ²¡æœ‰ä½ é¢„æœŸçš„ç†Ÿåº¦ã€‚è¿™ä¸ªæ°´æžœè¡¨é¢çœ‹æ¥å¯ä»¥åƒäº†ï¼Œç„¶è€Œè¿˜ç¼ºä¹ä¸€ä¸ªå› ç´ â€¦â€¦

æ—¶é—´ã€‚

å³ä½¿æ˜¯ä¸€ä¸ªæ‘˜æžœå­çš„ç®€å•åŠ¨ä½œï¼Œä¹Ÿèƒ½æ•™ä¼šæˆ‘ä»¬æ—¶é—´å’Œå¿è€çš„é‡è¦æ€§ï¼š

â€œå¼Ÿå…„ä»¬å“ªï¼Œä½ ä»¬è¦å¿è€ï¼Œç›´åˆ°ä¸»æ¥ã€‚çœ‹å“ªï¼Œå†œå¤«å¿è€ç­‰å€™åœ°é‡Œå®è´µçš„å‡ºäº§ï¼Œç›´åˆ°å¾—äº†ç§‹é›¨æ˜¥é›¨ã€‚ä½ ä»¬ä¹Ÿå½“å¿è€ï¼Œåšå›ºä½ ä»¬çš„å¿ƒï¼Œå› ä¸ºä¸»æ¥çš„æ—¥å­è¿‘äº†ã€‚ â€ï¼ˆé›…å„ä¹¦ 5:7-8ï¼‰

ä½œè€…é›…å„åœ¨åœ£çµçš„é»˜ç¤ºä¸‹ï¼Œç»™ä¸€ç¾¤æ–°å½’ä¿¡åŸºç£ä¸”åˆ†æ•£åœ¨å„ä¸ªåœ°åŒºçš„çŠ¹å¤ªäººå†™äº†è¿™ä¸€ç•ªè¯ã€‚è¿™äº›æ—©æœŸçš„åŸºç£å¾’å› ä»–ä»¬çš„åˆç”Ÿä¿¡ä»°è€Œé¢ä¸´è®¸å¤šè¯•ç‚¼ï¼ŒåŒ…æ‹¬è¿«å®³å’Œåå¯¹ã€‚é›…å„å¯¹ä»–ä»¬è¦è€å¿ƒç­‰å€™å’Œåšå¿çš„å‘¼åï¼Œä¸ä»…ä»…æ˜¯çº¸ä¸Šçš„æ–‡å­—ï¼Œæ›´æ˜¯é€†å¢ƒä¸­çš„ä¸€çº¿ç”Ÿæœºï¼Œä¸ºä»–ä»¬å¸¦æ¥ç›¼æœ›å’Œé¼“åŠ±ã€‚

æ­£å¦‚é‚£äº›æ—©æœŸä¿¡å¾’é¢ä¸´è¯•ç‚¼ä¸€æ ·ï¼Œæˆ‘ä»¬åœ¨åŸºç£ä¿¡ä»°çš„æ—…é€”ä¸­ä¹Ÿä¼šé‡åˆ°æŒ‘æˆ˜å’Œè‹¦éš¾ã€‚å› æ­¤ï¼Œä½ å¯ä»¥æ•ˆæ³•é‚£äº›æ—©æœŸçš„ä¿¡å¾’ä¸€æ ·é€‰æ‹©å¿è€ï¼›æ— è®ºä½ æ­£å¤„äºŽä»€ä¹ˆäººç”Ÿå¢ƒå†µï¼Œè®©åœ£çµçš„æžœå­åœ¨ä½ é‡Œé¢æˆç†Ÿã€‚å½“ä½ è¿™æ ·åšæ—¶ï¼Œä½ çš„å“æ ¼å°±ä¼šè€ç»ƒã€ä½ çš„ä¿¡å¿ƒå°±ä¼šåŠ æ·±ã€ä½ ä¸Žç¥žçš„å…³ç³»å°±ä¼šå˜å¾—æ¯”ä½ æƒ³è±¡çš„æ›´åŠ ç”˜ç”œã€‚å¿è€æ€»ä¼šç»“å‡ºæ¯…åŠ›å’ŒåŠ›é‡çš„æžœå­ã€‚ä»Šå¤©å°±å¼€å§‹æ¥æ“ç»ƒå§ï¼

ç¥·å‘Šâ€”
ç¥žå•Šï¼Œä½ æ˜¯å¿è€ä¸Žæ©æ…ˆçš„å®Œç¾Žå…¸èŒƒã€‚æ„Ÿè°¢ä½ ä¸€ç›´å¯¹æˆ‘çš„å¿è€ï¼è¯·ä½ æ˜¾æ˜Žæˆ‘ç”Ÿæ´»ä¸­éœ€è¦åŸ¹å…»å¿è€çš„å±‚é¢ã€‚æ±‚ä½ ç”¨ç›¼æœ›å’Œæ™ºæ…§æ¥å……æ»¡æˆ‘ï¼Œä»¥å¸®åŠ©æˆ‘ä¿¡é ä½ ï¼Œå°¤å…¶æ˜¯åœ¨æˆ‘é‡ä¸Šè‰°éš¾æŒ‘æˆ˜çš„æ—¶å€™ã€‚
å¥‰è€¶ç¨£çš„åï¼Œ
é˜¿ä»¬ã€‚
"""

# Generate filename dynamically
# 1. Extract Date
first_line = TEXT.strip().split('\n')[0]
date_match = re.search(r"(\d{1,2})/(\d{1,2})/(\d{4})", first_line)
if date_match:
    m, d, y = date_match.groups()
    date_str = f"{y}-{int(m):02d}-{int(d):02d}"
else:
    # Try YYYY-MM-DD
    date_match = re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", first_line)
    if date_match:
        y, m, d = date_match.groups()
        date_str = f"{y}-{int(m):02d}-{int(d):02d}"
    else:
        date_str = datetime.today().strftime("%Y-%m-%d")

# 2. Extract Verse (First parenthesis content)
verse_match = re.search(r"\((.*?)\)", TEXT)
verse_ref = verse_match.group(1).strip() if verse_match else "Unknown-Verse"

filename = filename_parser.generate_filename(verse_ref, date_str).replace(".mp3", "_cosy.mp3")
OUTPUT_DIR = os.getcwd()
OUTPUT_PATH = os.path.join(OUTPUT_DIR, filename)
print(f"Target Output: {OUTPUT_PATH}")

TEXT = convert_bible_reference(TEXT)
TEXT = convert_dates_in_text(TEXT)
TEXT = remove_space_before_god(TEXT)

paragraphs = [p.strip() for p in TEXT.strip().split("\n\n") if p.strip()]

# Built-in CosyVoice voices
# NOTE: CosyVoice SFT inference uses specific speaker names.
# Common ones: "ä¸­æ–‡å¥³", "ä¸­æ–‡ç”·", "æ—¥è¯­ç”·", "ç²¤è¯­å¥³", "è‹±æ–‡å¥³", "è‹±æ–‡ç”·", "éŸ©è¯­å¥³"
voices = ["ä¸­æ–‡å¥³", "ä¸­æ–‡ç”·", "è‹±æ–‡å¥³", "ä¸­æ–‡å¥³", "ä¸­æ–‡ç”·"]

def speak(text: str, voice: str) -> AudioSegment:
    # inference_sft returns a result iterable usually, or creates a generator
    # output format: {'tts_speech': tensor, 'samplerate': 22050}
    # It might return a generator, so we iterate
    
    print(f"   Synthesizing ({len(text)} chars) with {voice}...")
    output_gen = cosyvoice.inference_sft(text, voice)
    
    final_audio = AudioSegment.empty()
    
    # Iterate through the generator
    for item in output_gen:
        if 'tts_speech' in item:
            audio_np = item['tts_speech'].numpy()
            # Normalize float -1..1 to int16
            audio_int16 = (audio_np * 32767).astype(np.int16)
            segment = AudioSegment(
                audio_int16.tobytes(),
                frame_rate=22050, 
                sample_width=2,
                channels=1
            )
            final_audio += segment
            
    return final_audio

# Group paragraphs into 5 logical sections
if len(paragraphs) < 5:
    logical_sections = [[p] for p in paragraphs]
else:
    logical_sections = [
        [paragraphs[0]],              # Intro
        [paragraphs[1]],              # Scripture 1
        [paragraphs[2]],              # Scripture 2
        paragraphs[3:-1],             # Main Body
        [paragraphs[-1]]              # Prayer
    ]

print(f"Processing {len(logical_sections)} logical sections...")
# Voice mapping (Rotation)
# CosyVoice-300M-Instruct supports: ä¸­æ–‡å¥³, ä¸­æ–‡ç”·, æ—¥è¯­ç”·, ç²¤è¯­å¥³, è‹±æ–‡å¥³, è‹±æ–‡ç”·, éŸ©è¯­å¥³
# We add English Male and Japanese Male because they can speak Chinese too (Cross-lingual)
voices = ["ä¸­æ–‡å¥³", "è‹±æ–‡ç”·", "ä¸­æ–‡ç”·", "æ—¥è¯­ç”·", "ä¸­æ–‡å¥³"]
section_titles = ["Intro", "Scripture 1", "Scripture 2", "Main Body", "Prayer"]

final_segments = []
global_p_index = 0

for i, section_paras in enumerate(logical_sections):
    title = section_titles[i] if i < len(section_titles) else f"Section {i+1}"
    print(f"--- Section {i+1}: {title} ---")
    
    section_audio = AudioSegment.empty()
    silence_between_paras = AudioSegment.silent(duration=700, frame_rate=22050)

    for j, para in enumerate(section_paras):
        voice = voices[global_p_index % len(voices)]
        print(f"  > Part {i+1}.{j+1} - {voice}")
        global_p_index += 1
        current_segment = speak(para, voice)
        section_audio += current_segment
        
        if j < len(section_paras) - 1:
            section_audio += silence_between_paras
            
    final_segments.append(section_audio)

final = AudioSegment.empty()
silence_between_sections = AudioSegment.silent(duration=1000, frame_rate=22050)

for i, seg in enumerate(final_segments):
    final += seg
    if i < len(final_segments) - 1:
        final += silence_between_sections

# Convert to 24k for consistency with others if desired, or keep 22k
final = final.set_frame_rate(24000)
final.export(OUTPUT_PATH, format="mp3", bitrate="192k")
print(f"Success! Saved â†’ {OUTPUT_PATH}")
