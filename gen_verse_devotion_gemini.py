# gen_verse_devotion_gemini.py
# Google Gemini TTS ‚Äì Multi-voice, works with Google Cloud credentials

import io
import os
import re
from google.cloud import texttospeech
from pydub import AudioSegment

from bible_parser import convert_bible_reference
from date_parser import convert_dates_in_text
from text_cleaner import remove_space_before_god
import filename_parser
import re
from datetime import datetime

# Ensure Google Cloud credentials are set
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "/path/to/key.json" 
# Verify credentials exist
if not os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
    print("‚ö†Ô∏è WARNING: GOOGLE_APPLICATION_CREDENTIALS not set. Ensure you have authenticated via gcloud or set the env var.")



TEXT = """
Êàë‰ª¨ÁöÑÂ•ΩÁâß‰∫∫ (Á∫¶Áø∞Á¶èÈü≥ 10:10) 2025-12-12

ÊâÄ‰ª•Ôºå‰Ω†Ë¶ÅÁü•ÈÅìËÄ∂ÂíåÂçéÔºç‰Ω†ÁöÑ„ÄÄÁ•ûÔºå‰ªñÊòØ„ÄÄÁ•ûÔºåÊòØ‰ø°ÂÆûÁöÑ„ÄÄÁ•ûÔºõÂêëÁà±‰ªñ„ÄÅÂÆà‰ªñËØ´ÂëΩÁöÑ‰∫∫ÂÆàÁ∫¶ÔºåÊñΩÊÖàÁà±ÔºåÁõ¥Âà∞ÂçÉ‰ª£Ôºõ
(Áî≥ÂëΩËÆ∞ 7:9)
Âè§Êó∂ÔºàÊàñËØëÔºö‰ªéËøúÊñπÔºâËÄ∂ÂíåÂçéÂêë‰ª•Ëâ≤ÂàóÔºàÂéüÊñáÊòØÊàëÔºâÊòæÁé∞ÔºåËØ¥Ôºö
Êàë‰ª•Ê∞∏ËøúÁöÑÁà±Áà±‰Ω†Ôºå
Âõ†Ê≠§Êàë‰ª•ÊÖàÁà±Âê∏Âºï‰Ω†„ÄÇ
(ËÄ∂Âà©Á±≥‰π¶ 31:3 ÂíåÂêàÊú¨)
ËÄ∂ÂíåÂçéÂú®Âè§Êó∂Ôºà‚ÄúÂú®Âè§Êó∂‚ÄùÊàñËØëÔºö‚Äú‰ªéËøúÂ§Ñ‚ÄùÔºâÊõæÂêë‰ª•Ëâ≤ÂàóÔºàÊåâÁÖß„ÄäÈ©¨Á¥¢ÊãâÊñáÊú¨„ÄãÔºå‚Äú‰ª•Ëâ≤Âàó‚ÄùÂ∫î‰Ωú‚ÄúÊàë‚ÄùÔºõÁé∞ÂèÇÁÖß„Ää‰∏ÉÂçÅÂ£´ËØëÊú¨„ÄãÁøªËØëÔºâÊòæÁé∞ÔºåËØ¥Ôºö
‚ÄúÊàë‰ª•Ê∞∏ËøúÁöÑÁà±Áà±‰Ω†Ôºå
Âõ†Ê≠§ÔºåÊàëÂØπ‰Ω†ÁöÑÊÖàÁà±Âª∂Áª≠‰∏çÊÅØÔºà‚ÄúÊàëÂØπ‰Ω†ÁöÑÊÖàÁà±Âª∂Áª≠‰∏çÊÅØ‚ÄùÊàñËØëÔºö‚ÄúÊàëË¶Å‰ª•ÊÖàÁà±Âê∏Âºï‰Ω†‚ÄùÔºâ„ÄÇ
(ËÄ∂Âà©Á±≥‰π¶ 31:3 Êñ∞ËØëÊú¨)
‰ªéÂâçÔºåËÄ∂ÂíåÂçéÂêë‰ª•Ëâ≤ÂàóÊòæÁé∞ÔºåËØ¥Ôºö
‚ÄúÊàë‰ª•Ê∞∏ËøúÁöÑÁà±Áà±‰Ω†Ôºå
Êàë‰ª•‰∏çÂèòÁöÑÊÖàÁà±Âê∏Âºï‰Ω†„ÄÇ
(ËÄ∂Âà©Á±≥‰π¶ 31:3 ÂΩì‰ª£ËØëÊú¨)
‰Ω†‰∏çË¶ÅÂÆ≥ÊÄïÔºåÂõ†‰∏∫Êàë‰∏é‰Ω†ÂêåÂú®Ôºõ
‰∏çË¶ÅÊÉäÊÉ∂ÔºåÂõ†‰∏∫ÊàëÊòØ‰Ω†ÁöÑ„ÄÄÁ•û„ÄÇ
ÊàëÂøÖÂùöÂõ∫‰Ω†ÔºåÊàëÂøÖÂ∏ÆÂä©‰Ω†Ôºõ
ÊàëÂøÖÁî®ÊàëÂÖ¨‰πâÁöÑÂè≥ÊâãÊâ∂ÊåÅ‰Ω†„ÄÇ
(‰ª•Ëµõ‰∫ö‰π¶ 41:10)

ÊâÄ‰ª•ÔºåËÄ∂Á®£ÂèàÂØπ‰ªñ‰ª¨ËØ¥Ôºö‚ÄúÊàëÂÆûÂÆûÂú®Âú®Âú∞ÂëäËØâ‰Ω†‰ª¨ÔºåÊàëÂ∞±ÊòØÁæäÁöÑÈó®„ÄÇÂá°Âú®Êàë‰ª•ÂÖàÊù•ÁöÑÈÉΩÊòØË¥ºÔºåÊòØÂº∫ÁõóÔºõÁæäÂç¥‰∏çÂê¨‰ªñ‰ª¨„ÄÇÊàëÂ∞±ÊòØÈó®ÔºõÂá°‰ªéÊàëËøõÊù•ÁöÑÔºåÂøÖÁÑ∂ÂæóÊïëÔºåÂπ∂‰∏îÂá∫ÂÖ•ÂæóËçâÂêÉ„ÄÇÁõóË¥ºÊù•ÔºåÊó†ÈùûË¶ÅÂÅ∑Á™ÉÔºåÊùÄÂÆ≥ÔºåÊØÅÂùèÔºõÊàëÊù•‰∫ÜÔºåÊòØË¶ÅÂè´ÁæäÔºàÊàñËØëÔºö‰∫∫ÔºâÂæóÁîüÂëΩÔºåÂπ∂‰∏îÂæóÁöÑÊõ¥‰∏∞Áõõ„ÄÇÊàëÊòØÂ•ΩÁâß‰∫∫ÔºõÂ•ΩÁâß‰∫∫‰∏∫ÁæäËàçÂëΩ„ÄÇ
(Á∫¶Áø∞Á¶èÈü≥ 10:7-11 ÂíåÂêàÊú¨)
ÁõóË¥ºÊù•ÔºåÊó†ÈùûË¶ÅÂÅ∑Á™ÉÔºåÊùÄÂÆ≥ÔºåÊØÅÂùèÔºõÊàëÊù•‰∫ÜÔºåÊòØË¶ÅÂè´ÁæäÔºàÊàñËØëÔºö‰∫∫ÔºâÂæóÁîüÂëΩÔºåÂπ∂‰∏îÂæóÁöÑÊõ¥‰∏∞Áõõ„ÄÇ
(Á∫¶Áø∞Á¶èÈü≥ 10:10 ÂíåÂêàÊú¨)
Ë¥ºÊù•‰∫ÜÔºå‰∏çËøáÊòØË¶ÅÂÅ∑Á™É„ÄÅÊùÄÂÆ≥„ÄÅÊØÅÂùèÔºõÊàëÊù•‰∫ÜÔºåÊòØË¶Å‰ΩøÁæäÂæóÁîüÂëΩÔºåÂπ∂‰∏îÂæóÁöÑÊõ¥‰∏∞Áõõ„ÄÇ
(Á∫¶Áø∞Á¶èÈü≥ 10:10 Êñ∞ËØëÊú¨)

Êàë‰ª¨ÁöÑÂ•ΩÁâß‰∫∫

ËÄ∂Á®£Â§öÊ¨°‰ΩøÁî®ÁöÑ‚ÄúÊàëÊòØ‚ÄùÊòØ‰∏Ä‰∏™ÂæàÊúâÂäõÁöÑÂ£∞ÊòéÔºåËÆ©Êàë‰ª¨‰∏ÄÁû•ËÄ∂Á®£ÁöÑÊú¨ÊÄßÂíå‰ªñÂú®‰∏ñ‰∏äÁöÑ‰ΩøÂëΩ„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂ±ïÁé∞‰∫ÜËÄ∂Á®£Âú®‰∏ñ‰∏äÊâßË°å‰ΩøÂëΩÁöÑÁõÆÁöÑ‰∏éÂßøÊÄÅ„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂ∞ÜËÄ∂Á®£‰∏éÁà∂Á•ûËÅîÁ≥ªËµ∑Êù•ÔºõËÄ∂Á®£ÁöÑ‚ÄúÊàëÊòØ‚ÄùË°®Êòé‰∫Ü‰ªñÁöÑÁ•ûÊÄßÔºå‰∏éÂá∫ÂüÉÂèäËÆ∞ 3:14 ‰∏≠Á•ûÂêëÊë©Ë•øÂêØÁ§∫Ëá™Â∑±‰∏∫‚ÄúÊàëÊòØ‚ÄùÁöÑÂÆ£Ë®ÄÊÅØÊÅØÁõ∏ÂÖ≥„ÄÇ

Âú®Á∫¶Áø∞Á¶èÈü≥Á¨¨10Á´†‰∏≠ÔºåËÄ∂Á®£ÂëäËØâ‰∫∫‰ª¨‰ªñÊòØÂ•ΩÁâß‰∫∫„ÄÇÂ•ΩÁâß‰∫∫ÁöÑÊ†áÂøóÊòØ‰ªñÂøÖÈ°ªÊÑøÊÑè‰∏∫‰ªñÁöÑÁæäËàçÂëΩ„ÄÇËÄ∂Á®£ËØ¥‰ªñÊÑøÊÑèÈÇ£Ê†∑ÂÅö„ÄÇ

ËÄ∂Á®£ÁöÑËØù‰∏é‰ªñÈÇ£‰∏™Êó∂‰ª£ÁöÑÂÆóÊïôÈ¢ÜË¢ñÂΩ¢ÊàêÈ≤úÊòéÁöÑÂØπÊØî„ÄÇÈÇ£‰∫õÂÆóÊïôÈ¢ÜË¢ñÂ∏∏Â∏∏ÂàÅÈöæÁ•ûÁöÑËøΩÈöèËÄÖ„ÄÇ‰ªñ‰ª¨Ê∑ªÂä†ÂæãÊ≥ïÂíåÊù°ËßÑÔºåÂØºËá¥‰∫∫‰ª¨Êõ¥ËøúÁ¶ªÁ•û„ÄÇÂΩíÊ†πÁªìÂ∫ïÔºå‰ªñ‰ª¨ÊòØËá™ÁßÅÁöÑÈ¢ÜË¢ñÔºåËÆ§‰∏∫Ëá™Â∑±ÊØî‰ªñ‰ª¨ÊâÄÈ¢ÜÂØºÁöÑ‰∫∫Êõ¥ÈáçË¶Å„ÄÇ

ËÄ∂Á®£ÊåáÂá∫ÔºåÂÅöÂ•ΩÁâß‰∫∫ÁöÑÊúÄÈáçË¶ÅÊù°‰ª∂ÊòØ‰∏∫ÁæäËàçÂëΩ„ÄÇËÄ∂Á®£Â∞±ÊòØÈÇ£‰ΩçËá≥È´òÁöÑÁâßÁæä‰∫∫ÔºåÂõ†‰∏∫‰ªñÁúüÊ≠£ÂÖ≥ÂøÉÁ•ûÁöÑÂ≠êÊ∞ë„ÄÇ‰ªñÂ∞±ÂÉèËØóÁØá23ÁØá‰∏≠ÁöÑÁâßÁæä‰∫∫ÔºåÊääÁæäÁæ§È¢ÜÂà∞ÂèØÂÆâÊ≠áÁöÑÊ∞¥ËæπÔºå‰Ωø‰ªñ‰ª¨ÁöÑÁÅµÈ≠ÇËãèÈÜí„ÄÇ

‰Ω†ÊúâÊ≤°ÊúâÊÉ≥ËøáËÄ∂Á®£ÊòØ‰Ω†‰∏™‰∫∫ÁÅµÈ≠ÇÁöÑÁâß‰∫∫ÔºüËÄ∂Á®£ÂàáÊúõÂú®ÁîüÊ¥ª‰∏≠‰∏é‰Ω†ÂêåË°å„ÄÅÁÖßÈ°æ‰Ω†ÁöÑÈúÄÊ±ÇÔºåÂπ∂‰øùÂÆà‰Ω†ÁöÑÂøÉ„ÄÇ‰ªñ‰∏ÄÂøÉË¶ÅÁà±‰Ω†Âπ∂ÂºïÂØº‰Ω†ÂÅöÂØπ‰Ω†ÊúâÁõäÁöÑ‰∫ãÊÉÖ„ÄÇ 

‰ªñ‰∏çÊòØ‰∏Ä‰∏™ÊÉ≥ËÆ©‰Ω†ÁöÑÁîüÊ¥ªÂèòÂæóÊ≤âÈáçÊàñÂõ∞ÈöæÁöÑÂºïÈ¢ÜËÄÖ„ÄÇÁõ∏ÂèçÔºå‰ªñÂ∏åÊúõ‰Ω†Ê¥ªÂú®Ëá™Áî±ÂíåÊÅ©ÂÖ∏‰∏≠„ÄÇËä±ÁÇπÊó∂Èó¥Êù•ÊÄùÊÉ≥ËÄ∂Á®£ÊòØ‰Ω†ÁöÑÂ•ΩÁâß‰∫∫ÁöÑÂê´‰πâÔºåÂπ∂ÊÑüË∞¢‰ªñÁöÑÁà±ÂíåÊÅ©ÂÖ∏„ÄÇ

Á•∑ÂëäÔºö
Á•ûÂïäÔºåÊÑüË∞¢‰Ω†ÂÅöÊàëÁöÑÂ•ΩÁâß‰∫∫„ÄÇÂç≥‰ΩøÂú®ÊàëÊÄÄÁñë‰Ω†ÁöÑËâØÂñÑÁöÑÊó∂ÂÄôÔºå‰Ω†‰ªçÊó†ÁßÅÂú∞ÂØªÊ±ÇÊàë„ÄÇ‰Ω†‰∏ÄÊ¨°Âèà‰∏ÄÊ¨°Âú∞‰ΩøÊàëÁÑ¶ËôëÁöÑÂøÉÂπ≥Èùô‰∏ãÊù•„ÄÇÊÑüË∞¢‰Ω†ËÉåË¥üÊàëÁöÑÈáçÊãÖ„ÄÇÊàëÁü•ÈÅì‰Ω†Áú∑È°æÊàëÔºåÂπ∂‰∏îÊÄªÊòØ‰∏∫ÊàëÁöÑÁõäÂ§ÑÁùÄÊÉ≥„ÄÇÂ•âËÄ∂Á®£ÁöÑÂêçÔºåÈòø‰ª¨„ÄÇ
"""

# Generate filename dynamically
# 1. Extract Date
first_line = TEXT.strip().split('\n')[0]
date_match = re.search(r"(\d{1,2})/(\d{1,2})/(\d{4})", first_line)
if date_match:
    m, d, y = date_match.groups()
    date_str = f"{y}-{int(m):02d}-{int(d):02d}"
else:
    # Try YYYY-MM-DD
    date_match = re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", first_line)
    if date_match:
        y, m, d = date_match.groups()
        date_str = f"{y}-{int(m):02d}-{int(d):02d}"
    else:
        date_str = datetime.today().strftime("%Y-%m-%d")

# 2. Extract Verse (First parenthesis content)
verse_match = re.search(r"\((.*?)\)", TEXT)
verse_ref = verse_match.group(1).strip() if verse_match else "Unknown-Verse"

filename = filename_parser.generate_filename(verse_ref, date_str).replace(".mp3", "_gemini.mp3")
OUTPUT_PATH = f"/Users/mhuo/Downloads/{filename}"
print(f"Target Output: {OUTPUT_PATH}")

TEXT = convert_bible_reference(TEXT)
TEXT = convert_dates_in_text(TEXT)
TEXT = remove_space_before_god(TEXT)

paragraphs = [p.strip() for p in TEXT.strip().split("\n\n") if p.strip()]

# Supported Gemini/Google Voices
# Using a mix of male/female voices for variety
voices = ["Charon", "Kore", "Fenrir", "Aoede", "Puck"]

# Voice configuration
LANGUAGE_CODE = "cmn-CN"
MODEL_NAME = "gemini-2.5-pro-tts" # Or appropriate model

# Global client cache
_TTS_CLIENT = None

def get_tts_client():
    global _TTS_CLIENT
    if _TTS_CLIENT:
        return _TTS_CLIENT

    try:
        # Try default credentials first
        _TTS_CLIENT = texttospeech.TextToSpeechClient()
        return _TTS_CLIENT
    except Exception as e:
        print(f"‚ö†Ô∏è Default auth failed: {e}")
        print("üîÑ Attempting to use gcloud access token...")
        
        try:
            import subprocess
            import google.oauth2.credentials
            from google.api_core.client_options import ClientOptions
            
            # Get token via gcloud
            result = subprocess.run(
                ["zsh", "-l", "-c", "gcloud auth print-access-token"],
                capture_output=True,
                text=True,
                check=True
            )
            token = result.stdout.strip()
            
            # Get project ID via gcloud for quota
            project_result = subprocess.run(
                ["zsh", "-l", "-c", "gcloud config get-value project"],
                capture_output=True,
                text=True,
                check=True
            )
            project_id = project_result.stdout.strip()
            
            if not token:
                raise ValueError("Empty token received from gcloud")
                
            creds = google.oauth2.credentials.Credentials(token=token)
            
            # Set quota project to fix 403 error
            client_options = ClientOptions(quota_project_id=project_id) if project_id else None
            
            _TTS_CLIENT = texttospeech.TextToSpeechClient(credentials=creds, client_options=client_options)
            print(f"‚úÖ Successfully authenticated using gcloud access token (Project: {project_id}).")
            return _TTS_CLIENT
            
        except Exception as token_error:
            print(f"‚ùå Failed to get gcloud token/project: {token_error}")
            raise e


def chunk_text(text: str, max_len: int = 400) -> list[str]:
    """Split text if too long (though Google limit is high, good practice)."""
    if len(text) <= max_len:
        return [text]
    chunks = []
    current_chunk = ""
    parts = re.split(r'([„ÄÇÔºÅÔºüÔºõ!.?\n]+)', text)
    for part in parts:
        if len(current_chunk) + len(part) < max_len:
            current_chunk += part
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = part
    if current_chunk:
        chunks.append(current_chunk)
    return chunks

def speak(text: str, voice: str, style_prompt: str = None) -> AudioSegment:
    client = get_tts_client()
    synthesis_input = texttospeech.SynthesisInput(text=text)
    
    # Selecting voice
    voice_params = texttospeech.VoiceSelectionParams(
        language_code=LANGUAGE_CODE,
        name=voice,
        # Enable model name for Gemini voices
        model_name=MODEL_NAME 
    )
    
    # Audio config
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )
    
    # Request
    request = texttospeech.SynthesizeSpeechRequest(
        input=synthesis_input,
        voice=voice_params,
        audio_config=audio_config
    )
    
    # If style prompt is provided... (same logic as before)
    if style_prompt:
         try:
             synthesis_input = texttospeech.SynthesisInput(text=text, prompt=style_prompt)
             # Re-assign input to request
             request.input = synthesis_input
         except TypeError:
             print(f"‚ö†Ô∏è Warning: 'prompt' not supported in SynthesisInput for this client version. Ignoring prompt: {style_prompt}")

    
    response = client.synthesize_speech(request=request)
    
    # Load into pydub
    return AudioSegment.from_mp3(io.BytesIO(response.audio_content))

# Group paragraphs into 5 logical sections
# 1. Intro (Title/Date)
# 2. Scripture 1
# 3. Scripture 2
# 4. Main Body (Middle paragraphs)
# 5. Prayer (Last paragraph)

if len(paragraphs) < 5:
    # Fallback
    logical_sections = [[p] for p in paragraphs]
else:
    logical_sections = [
        [paragraphs[0]],              # Intro
        [paragraphs[1]],              # Scripture 1
        [paragraphs[2]],              # Scripture 2
        paragraphs[3:-1],             # Main Body
        [paragraphs[-1]]              # Prayer
    ]

# Ensure we don't exceed available voices
num_sections = len(logical_sections)
section_titles = ["Intro", "Scripture 1", "Scripture 2", "Main Body", "Prayer"]

# Define Style Prompts for each section
# These prompts help guide the "Gemini" model to adopt the correct tone
section_styles = [
    "Speak with a clear, professional, announcer-like tone for a title introduction.", # Intro
    "Speak with a solemn, reverent, and slow pace, suitable for reading Holy Scripture.", # Scripture 1
    "Speak with a solemn, reverent, and slow pace, suitable for reading Holy Scripture.", # Scripture 2
    "Speak with a warm, engaging, and personal storytelling tone, like a friend sharing wisdom.", # Main Body
    "Speak with a humble, quiet, and earnest tone, suitable for prayer.", # Prayer
]

print(f"Processing {num_sections} logical sections...")

final_segments = []
global_p_index = 0

for i, section_paras in enumerate(logical_sections):
    title = section_titles[i] if i < len(section_titles) else f"Section {i+1}"
    style_prompt = section_styles[i] if i < len(section_styles) else None
    
    print(f"--- Section {i+1}: {title} ---")
    if style_prompt:
        print(f"  [Style Prompt]: {style_prompt}")
    
    section_audio = AudioSegment.empty()
    # Assuming silence same as 'silence' defined later, but we need it here.
    # We'll use 24000 as default or detect from first segment if available.
    silence_between_paras = AudioSegment.silent(duration=700, frame_rate=24000)

    for j, para in enumerate(section_paras):
        voice = voices[global_p_index % len(voices)]
        print(f"  > Part {i+1}.{j+1} - {voice} ({len(para)} chars)")
        global_p_index += 1
        
        current_segment = AudioSegment.empty()
        # Check length
        if len(para) > 1000:
            chunks = chunk_text(para, 1000)
            print(f"    Split into {len(chunks)} chunks due to length.")
            for chunk in chunks:
                if chunk.strip():
                    current_segment += speak(chunk, voice, style_prompt)
        else:
            current_segment = speak(para, voice, style_prompt)
            
        section_audio += current_segment
        
        if j < len(section_paras) - 1:
            section_audio += silence_between_paras
            
    final_segments.append(section_audio)

final = AudioSegment.empty()

# Determine sample rate from first segment to ensure consistency
# Determine sample rate from first segment to ensure consistency
frame_rate = final_segments[0].frame_rate if final_segments else 24000
silence = AudioSegment.silent(duration=1000, frame_rate=frame_rate)

for i, seg in enumerate(final_segments):
    final += seg
    if i < len(final_segments) - 1:
        final += silence

final.export(OUTPUT_PATH, format="mp3", bitrate="192k")
print(f"Success! Saved ‚Üí {OUTPUT_PATH}")
