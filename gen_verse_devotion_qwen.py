
# gen_verse_devotion_qwen.py
# Real Qwen3-TTS â€“ 5 voices, works perfectly

import io
import os
import sys
import requests
import dashscope
from dashscope.audio.qwen_tts import SpeechSynthesizer
from pydub import AudioSegment

from bible_parser import convert_bible_reference
from date_parser import convert_dates_in_text
from text_cleaner import clean_text
import filename_parser
import audio_mixer
import re
from datetime import datetime

import argparse

# CLI Args
if "-?" in sys.argv:
    print(f"Usage: python {sys.argv[0]} [--prefix PREFIX] [--bgm] [--bgm-track TRACK] [--bgm-volume VOL] [--bgm-intro MS] [--help]")
    print ("\nOptions:")
    print("  --prefix PREFIX      Filename prefix (e.g. MyPrefix)")
    print("  --bgm                Enable background music (Default: False)")
    print("  --bgm-track TRACK    Specific BGM filename (Default: AmazingGrace.MP3)")
    print("  --bgm-volume VOL     BGM volume adjustment in dB (Default: -20)")
    print("  --bgm-intro MS       BGM intro delay in ms (Default: 4000)")
    print("  --help, -h           Show this help")
    print("\n  (Note: You can also add 'FilenamePrefix: <Prefix>' in the input TEXT)")
    sys.exit(0)

parser = argparse.ArgumentParser()
parser.add_argument("--prefix", type=str, default=None, help="Filename prefix (e.g. MyPrefix)")
parser.add_argument("--bgm", action="store_true", help="Enable background music (Default: False)")
parser.add_argument("--bgm-track", type=str, default="AmazingGrace.MP3", help="Specific BGM filename (Default: AmazingGrace.MP3)")
parser.add_argument("--bgm-volume", type=int, default=-20, help="BGM volume adjustment in dB (Default: -20)")
parser.add_argument("--bgm-intro", type=int, default=4000, help="BGM intro delay in ms (Default: 4000)")

args, unknown = parser.parse_known_args()
CLI_PREFIX = args.prefix
ENABLE_BGM = args.bgm
BGM_FILE = args.bgm_track
BGM_VOLUME = args.bgm_volume
BGM_INTRO_DELAY = args.bgm_intro

TEXT = """
ç¥žåœ¨å†™çš„æ•…äº‹ (è·¯åŠ ç¦éŸ³ 1:46-48) 12/21/2025

æˆ‘å› è€¶å’ŒåŽå¤§å¤§æ¬¢å–œï¼›
æˆ‘çš„å¿ƒé ã€€ç¥žå¿«ä¹ã€‚
å› ä»–ä»¥æ‹¯æ•‘ä¸ºè¡£ç»™æˆ‘ç©¿ä¸Šï¼Œ
ä»¥å…¬ä¹‰ä¸ºè¢ç»™æˆ‘æŠ«ä¸Šï¼Œ
å¥½åƒæ–°éƒŽæˆ´ä¸ŠåŽå† ï¼Œ
åˆåƒæ–°å¦‡ä½©æˆ´å¦†é¥°ã€‚
ç”°åœ°æ€Žæ ·ä½¿ç™¾è°·å‘èŠ½ï¼Œ
å›­å­æ€Žæ ·ä½¿æ‰€ç§çš„å‘ç”Ÿï¼Œ
ä¸»è€¶å’ŒåŽå¿…ç…§æ ·
ä½¿å…¬ä¹‰å’Œèµžç¾Žåœ¨ä¸‡æ°‘ä¸­å‘å‡ºã€‚
(ä»¥èµ›äºšä¹¦ 61:10-11)
å¹¶ä¸”è€¶å’ŒåŽæ•‘èµŽçš„æ°‘å¿…å½’å›žï¼Œ
æ­Œå”±æ¥åˆ°é”¡å®‰ï¼›
æ°¸ä¹å¿…å½’åˆ°ä»–ä»¬çš„å¤´ä¸Šï¼›
ä»–ä»¬å¿…å¾—ç€æ¬¢å–œå¿«ä¹ï¼Œ
å¿§æ„å¹æ¯å°½éƒ½é€ƒé¿ã€‚
(ä»¥èµ›äºšä¹¦ 35:10)

é©¬åˆ©äºšè¯´ï¼š
æˆ‘å¿ƒå°Šä¸»ä¸ºå¤§ï¼›
æˆ‘çµä»¥ã€€ç¥žæˆ‘çš„æ•‘ä¸»ä¸ºä¹ï¼›
å› ä¸ºä»–é¡¾å¿µä»–ä½¿å¥³çš„å‘å¾®ï¼›
ä»Žä»Šä»¥åŽï¼Œ
ä¸‡ä»£è¦ç§°æˆ‘æœ‰ç¦ã€‚
(è·¯åŠ ç¦éŸ³ 1:46-48)

ç¥žåœ¨å†™çš„æ•…äº‹

é©¬åˆ©äºšæˆä¸ºæ¯äº²çš„åŽ†ç¨‹ç›¸å½“ç‹¬ç‰¹ï¼›ä¸€ä¸ªæœªå©šçš„å¤„å¥³æ€€ç€ç¥žçš„å„¿å­ã€‚é©¬åˆ©äºšè‚¯å®šæ„Ÿåˆ°å­¤ç‹¬æˆ–å­¤ç«‹ï¼Œä½†å¥¹åœ¨ç¥žè¦å†™çš„æ•…äº‹ä¸­å¹¶ä¸å­¤å•ã€‚

å‡ åå¹´æ¥ï¼Œé©¬åˆ©äºšçš„äº²æˆšä¼Šåˆ©èŽŽç™½å’Œå¥¹çš„ä¸ˆå¤«æ’’è¿¦åˆ©äºšä¸€ç›´éƒ½åœ¨å‘ç¥žç¥·å‘Šç¥ˆæ±‚ä¸€ä¸ªå­©å­ã€‚å¤šå¹´åŽï¼Œç¥žåº”å…äº†ä»–ä»¬çš„ç¥·å‘Šã€‚å½“ä¸€ä½å¤©ä½¿å‘Šè¯‰é©¬åˆ©äºšå¥¹å°†ç”Ÿä¸‹ä¸–ç•Œçš„æ•‘ä¸»è€¶ç¨£åŽï¼Œé©¬åˆ©äºšå°±æ€¥å¿™åŽ»æ‰¾ä¼Šåˆ©èŽŽç™½ã€‚å½“æ—¶ä¼Šåˆ©èŽŽç™½å·²ç»å¥‡è¿¹åœ°æ€€å­•å‡ ä¸ªæœˆäº†ã€‚

ä¼Šåˆ©èŽŽç™½ä¸€å¬åˆ°é©¬åˆ©äºšåœ¨æŠµè¾¾æ—¶çš„é—®å€™ï¼Œè‚šå­é‡Œçš„å©´å„¿å°±è·³äº†èµ·æ¥ã€‚ä¼Šåˆ©èŽŽç™½å……æ»¡äº†åœ£çµï¼Œâ€œé«˜å£°å–Šç€è¯´ï¼šâ€˜ä½ åœ¨å¦‡å¥³ä¸­æ˜¯æœ‰ç¦çš„ï¼ä½ æ‰€æ€€çš„èƒŽä¹Ÿæ˜¯æœ‰ç¦çš„ï¼â€ï¼ˆè·¯åŠ ç¦éŸ³ 1:42ï¼‰

åˆ«å¿˜äº†é©¬åˆ©äºšä¹Ÿåˆšåˆšå‘çŽ°è‡ªå·±æ€€å­•äº†ã€‚å¥¹æ„Ÿåˆ°ä¸çŸ¥æ‰€æŽªã€å®³æ€•æˆ–è‹¦æ¼æ˜¯å¯ä»¥ç†è§£çš„ã€‚æ›´ä¸ç”¨è¯´å¥¹å½“æ—¶éƒ½è¿˜æ²¡æœ‰å«ç»™çº¦ç‘Ÿã€‚ç„¶è€Œï¼Œçœ‹çœ‹å¥¹å›žç­”ä¸­çš„ä¿¡é å’Œä¿¡å¿ƒï¼š

â€œé©¬åˆ©äºšè¯´ï¼šæˆ‘å¿ƒå°Šä¸»ä¸ºå¤§ï¼›æˆ‘çµä»¥ç¥žæˆ‘çš„æ•‘ä¸»ä¸ºä¹ï¼›â€ï¼ˆè·¯åŠ ç¦éŸ³ 1:46-47ï¼‰

é©¬åˆ©äºšå’Œä¼Šåˆ©èŽŽç™½ä¸€èµ·åº¦è¿‡ä¸‰ä¸ªæœˆçš„æ—¶é—´ï¼Œå…±åŒç§°é¢‚ç¥žçš„ä½œä¸ºã€‚æƒ³è±¡ä¸€ä¸‹å¥¹ä»¬ä¹‹é—´è‚¯å®šæœ‰è®¨è®ºè¿‡çš„è¯é¢˜ï¼šé¢„è¨€çš„åº”éªŒï¼›ç¥žçš„å›½çš„æœªæ¥ï¼›ä¸¤ä¸ªå„¿å­æœªæ¥çš„äººç”Ÿé“è·¯ã€‚

é©¬åˆ©äºšé€‰æ‹©ä¸ºç¥žæ­£åœ¨å†™çš„æ•…äº‹è€Œæ¬¢æ¬£é¼“èˆžï¼›é‚£æ˜¯ä¸€ä¸ªä¿¡é å’Œç§°é¢‚ç¥žçš„å·¥çš„æ•…äº‹ã€‚

ä»Šå¤©ï¼Œé©¬åˆ©äºšçš„æ•…äº‹å¦‚ä½•é¼“åŠ±ä½ è¦ä¿¡é ç¥žï¼Ÿä½ å¯¹ç¥žåœ¨ä½ ç”Ÿå‘½ä¸­å†™çš„æ•…äº‹æœ‰ä»€ä¹ˆå›žåº”ï¼ŸèŠ±ç‚¹æ—¶é—´æ€è€ƒä½ ä»Šå¤©å¯ä»¥æ€Žæ ·è£è€€ä¸»å¹¶ä¸”ä»¥ä»–ä¸ºä¹ã€‚

ç¦±å‘Š
ç¥žå•Šï¼Œä½ å€¼å¾—æˆ‘æ¯«æ— ä¿ç•™çš„ä¿¡é ã€‚æˆ‘è¦åƒé©¬åˆ©äºšä¸€æ ·ä¿¡é ä½ ï¼Œå®Œå…¨ä¸å—è®¡åˆ’å˜åŒ–çš„å½±å“ï¼Œæ— è®ºå‘ç”Ÿä»€ä¹ˆéƒ½èƒ½ä»¥ä½ ä¸ºä¹ï¼æ„Ÿè°¢ä½ æ´¾äº†ä¸€ä½æ•‘ä¸»æ¥ç»™æˆ‘ç”Ÿå‘½ã€ç›¼æœ›å’Œä¸€ä¸ªæœªæ¥ã€‚æˆ‘çŸ¥é“æˆ‘å¯ä»¥ä¿¡é ä½ ï¼å¥‰è€¶ç¨£çš„åï¼Œé˜¿ä»¬ã€‚
"""


dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")
if not dashscope.api_key:
    raise ValueError("Please set DASHSCOPE_API_KEY in ~/.secrets")



# Generate filename dynamically
# 1. Extract Date
TEXT = clean_text(TEXT)
first_line = TEXT.strip().split('\n')[0]
date_match = re.search(r"(\d{1,2})/(\d{1,2})/(\d{4})", first_line)
if date_match:
    m, d, y = date_match.groups()
    date_str = f"{y}-{int(m):02d}-{int(d):02d}"
else:
    # Try YYYY-MM-DD
    date_match = re.search(r"(\d{4})-(\d{1,2})-(\d{1,2})", first_line)
    if date_match:
        y, m, d = date_match.groups()
        date_str = f"{y}-{int(m):02d}-{int(d):02d}"
    else:
        date_str = datetime.today().strftime("%Y-%m-%d")

# 2. Extract Verse
verse_ref = filename_parser.extract_verse_from_text(TEXT)

if verse_ref:
    extracted_prefix = CLI_PREFIX if CLI_PREFIX else filename_parser.extract_filename_prefix(TEXT)
    filename = filename_parser.generate_filename(verse_ref, date_str, extracted_prefix).replace(".mp3", "_qwen.mp3")
else:
    filename = f"{date_str}_qwen.mp3"

if ENABLE_BGM and BGM_FILE:
    bgm_base = os.path.splitext(os.path.basename(BGM_FILE))[0]
    filename = filename.replace(".mp3", f"_bgm_{bgm_base}.mp3")
OUTPUT_DIR = os.path.join(os.getcwd(), "output")
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
OUTPUT_PATH = os.path.join(OUTPUT_DIR, filename)
print(f"Target Output: {OUTPUT_PATH}")

TEXT = convert_bible_reference(TEXT)
TEXT = convert_dates_in_text(TEXT)
TEXT = clean_text(TEXT)

paragraphs = [p.strip() for p in re.split(r'\n{2,}', TEXT.strip()) if p.strip()]
# Supported Qwen-TTS voices
voices = ["Cherry", "Serena", "Ethan", "Chelsie", "Cherry"]

def chunk_text(text: str, max_len: int = 400) -> list[str]:
    if len(text) <= max_len:
        return [text]
    import re
    chunks = []
    current_chunk = ""
    parts = re.split(r'([ã€‚ï¼ï¼Ÿï¼›!.?\n]+)', text)
    for part in parts:
        if len(current_chunk) + len(part) < max_len:
            current_chunk += part
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = part
    if current_chunk:
        chunks.append(current_chunk)
    return chunks

def speak(text: str, voice: str) -> AudioSegment:
    print(f"DEBUG: Text to read: {text[:100]}...")
    resp = SpeechSynthesizer.call(
        model="qwen-tts",
        text=text,
        voice=voice,
        format="wav",
        sample_rate=24000
    )
    if resp.status_code != 200:
        raise Exception(f"API Error: {resp.message}")
    
    # Qwen-TTS returns a URL, we need to download it
    audio_url = resp.output.audio["url"]
    audio_data = requests.get(audio_url).content
    return AudioSegment.from_wav(io.BytesIO(audio_data))

# Group paragraphs into 5 logical sections
# 1. Intro (Title/Date)
# 2. Scripture 1
# 3. Scripture 2
# 4. Main Body (Middle paragraphs)
# 5. Prayer (Last paragraph)

if len(paragraphs) < 5:
    # Fallback if text is too short, just treat as list
    logical_sections = [[p] for p in paragraphs]
else:
    logical_sections = [
        [paragraphs[0]],              # Intro
        [paragraphs[1]],              # Scripture 1
        [paragraphs[2]],              # Scripture 2
        paragraphs[3:-1],             # Main Body (List of paragraphs)
        [paragraphs[-1]]              # Prayer
    ]

# Ensure we don't exceed available voices
num_sections = len(logical_sections)
section_titles = ["Intro", "Scripture 1", "Scripture 2", "Main Body", "Prayer"]
print(f"Processing {num_sections} logical sections...")

final_segments = []
global_p_index = 0

for i, section_paras in enumerate(logical_sections):
    title = section_titles[i] if i < len(section_titles) else f"Section {i+1}"
    print(f"--- Section {i+1}: {title} ---")
    
    section_audio = AudioSegment.empty()
    silence_between_paras = AudioSegment.silent(duration=700, frame_rate=24000)

    for j, para in enumerate(section_paras):
        # Cycle voices based on global paragraph count to match original behavior
        voice = voices[global_p_index % len(voices)]
        print(f"  > Part {i+1}.{j+1} - {voice} ({len(para)} chars)")
        global_p_index += 1
        
        # Check length and chunk if needed
        if len(para) > 450:
            chunks = chunk_text(para, 400)
            print(f"    Split into {len(chunks)} chunks due to length.")
            para_audio = AudioSegment.empty()
            for chunk in chunks:
                if chunk.strip():
                    para_audio += speak(chunk, voice)
            current_segment = para_audio
        else:
            current_segment = speak(para, voice)
            
        section_audio += current_segment
        
        # Add silence between paragraphs in the same section
        if j < len(section_paras) - 1:
            section_audio += silence_between_paras
            
    final_segments.append(section_audio)

final = AudioSegment.empty()
silence_between_sections = AudioSegment.silent(duration=1000, frame_rate=24000)

for i, seg in enumerate(final_segments):
    final += seg
    if i < len(final_segments) - 1:
        final += silence_between_sections

# Add Background Music (Optional)
if ENABLE_BGM:
    print(f"ðŸŽµ Mixing Background Music (Vol={BGM_VOLUME}dB, Intro={BGM_INTRO_DELAY}ms)...")
    final = audio_mixer.mix_bgm(
        final, 
        specific_filename=BGM_FILE,
        volume_db=BGM_VOLUME,
        intro_delay_ms=BGM_INTRO_DELAY
    )

# Metadata extraction
PRODUCER = "VI AI Foundation"
TITLE = TEXT.strip().split('\n')[0]

final.export(OUTPUT_PATH, format="mp3", bitrate="192k", tags={'title': TITLE, 'artist': PRODUCER})
print(f"Success! Saved â†’ {OUTPUT_PATH}")
